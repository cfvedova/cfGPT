{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d90213b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import scanpy as sc\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Softmax\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.optimize import nnls\n",
    "from scipy import sparse\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c465b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection:\n",
    "# Removal of uninformative genes that have either 0 expression or expression variance below 0.1. (10k genes for training left)\n",
    "# Don't care about dataset issues. Our job is just to genereate bulkRNAseq data\n",
    "\n",
    "#Metrics for comparison: RMSE, Pearson's corellation coefficient, the slope + intercept of regression fitted for ground0truth and predicted cell fractions, and Lin's concordance correlation coefficient\n",
    "#Measure it's failure to generalize\n",
    "\n",
    "#NOTE: making simulated data more similar to bulk data can improve performance\n",
    "\n",
    "#Preprocessing:\n",
    "#Corresponding cell-gene matrices, filtered for cells with less than 500 detected genes and genes expressed in less than five cells\n",
    "#Count matrix was filtered for outliers w/ high or low numbers of counts\n",
    "#Gene expression was normalized to library size via scanpy.normalize_per_cell\n",
    "#Data was saved\n",
    "#Cell type labels were reassigned to make it consistent across datasets\n",
    "#Important: preprocessed scRNAseq data was used (gene expression matrix and cell type labels)\n",
    "#How do we plan to keep within-subject relationships?\n",
    "#Take rand of whole list of cell types\n",
    "#list must add to 1\n",
    "#Multiply list by total number of cells per sample to get cells per type\n",
    "#Sample each number of cells from their appropriate cell type (Nc cells of cell type c)\n",
    "#Overcount if necessary\n",
    "#Take all results and add them together to get aggregated cell expressions\n",
    "\n",
    "#Also create \"Sparse Samples\" to be samples missing cell types or having a bias as to certain cell types\n",
    "#First, randomly drop a certain number of cell types. Then, drop them. Then, proceed as above\n",
    "\n",
    "#Low expression valued genes were removed\n",
    "#data transformed into log space\n",
    "# Add 1 and take log, base 2\n",
    "# scale using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa59f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What I need to do:\n",
    "#1. Have expression vals\n",
    "#2. Need to filter outlier cells\n",
    "#3. Normalize to library too\n",
    "#4. Save data\n",
    "#5. Load data\n",
    "#6. Generate lists of random numbers per sample we want\n",
    "#7. Sample num of cells from appropriate cell type\n",
    "#8. Aggregate expression values. Store as one input data\n",
    "#9. Have sparse samples to create sparse ones too\n",
    "#10. Save data\n",
    "#11. Data transform into log space then scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15947de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of cfrna_data:\n",
      "           Expression\n",
      "GeneName            \n",
      "OR4F5       0.000000\n",
      "OR4F29      0.000000\n",
      "OR4F16      0.000000\n",
      "SAMD11      3.119614\n",
      "NOC2L       4.175462\n",
      "...              ...\n",
      "MT-ND4L     5.746842\n",
      "MT-ND4      8.235097\n",
      "MT-ND5      8.278623\n",
      "MT-ND6      7.389071\n",
      "MT-CYB      8.207368\n",
      "\n",
      "[20012 rows x 1 columns]\n",
      "Contents of cfrna_df:\n",
      " GeneName        A1BG      A1CF       A2M     A2ML1   A3GALT2    A4GALT  \\\n",
      "Expression  2.273285  3.943163  4.693073  4.905578  2.150275  3.131951   \n",
      "Expression  2.273285  3.943163  4.693073  4.905578  2.150275  3.131951   \n",
      "Expression  2.273285  3.943163  4.693073  4.905578  2.150275  3.131951   \n",
      "Expression  2.273285  3.943163  4.693073  4.905578  2.150275  3.131951   \n",
      "Expression  2.273285  3.943163  4.693073  4.905578  2.150275  3.131951   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "Expression  2.273285  3.943163  4.693073  4.905578  2.150275  3.131951   \n",
      "Expression  2.273285  3.943163  4.693073  4.905578  2.150275  3.131951   \n",
      "Expression  2.273285  3.943163  4.693073  4.905578  2.150275  3.131951   \n",
      "Expression  2.273285  3.943163  4.693073  4.905578  2.150275  3.131951   \n",
      "Expression  2.273285  3.943163  4.693073  4.905578  2.150275  3.131951   \n",
      "\n",
      "GeneName       A4GNT      AAAS    AACS     AADAC  ...    ZWILCH     ZWINT  \\\n",
      "Expression  2.527434  4.041658  5.0649  2.009983  ...  3.300779  3.269217   \n",
      "Expression  2.527434  4.041658  5.0649  2.009983  ...  3.300779  3.269217   \n",
      "Expression  2.527434  4.041658  5.0649  2.009983  ...  3.300779  3.269217   \n",
      "Expression  2.527434  4.041658  5.0649  2.009983  ...  3.300779  3.269217   \n",
      "Expression  2.527434  4.041658  5.0649  2.009983  ...  3.300779  3.269217   \n",
      "...              ...       ...     ...       ...  ...       ...       ...   \n",
      "Expression  2.527434  4.041658  5.0649  2.009983  ...  3.300779  3.269217   \n",
      "Expression  2.527434  4.041658  5.0649  2.009983  ...  3.300779  3.269217   \n",
      "Expression  2.527434  4.041658  5.0649  2.009983  ...  3.300779  3.269217   \n",
      "Expression  2.527434  4.041658  5.0649  2.009983  ...  3.300779  3.269217   \n",
      "Expression  2.527434  4.041658  5.0649  2.009983  ...  3.300779  3.269217   \n",
      "\n",
      "GeneName        ZXDA      ZXDB      ZXDC    ZYG11A    ZYG11B       ZYX  \\\n",
      "Expression  3.055537  3.436174  4.250322  3.361063  3.617654  5.244687   \n",
      "Expression  3.055537  3.436174  4.250322  3.361063  3.617654  5.244687   \n",
      "Expression  3.055537  3.436174  4.250322  3.361063  3.617654  5.244687   \n",
      "Expression  3.055537  3.436174  4.250322  3.361063  3.617654  5.244687   \n",
      "Expression  3.055537  3.436174  4.250322  3.361063  3.617654  5.244687   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "Expression  3.055537  3.436174  4.250322  3.361063  3.617654  5.244687   \n",
      "Expression  3.055537  3.436174  4.250322  3.361063  3.617654  5.244687   \n",
      "Expression  3.055537  3.436174  4.250322  3.361063  3.617654  5.244687   \n",
      "Expression  3.055537  3.436174  4.250322  3.361063  3.617654  5.244687   \n",
      "Expression  3.055537  3.436174  4.250322  3.361063  3.617654  5.244687   \n",
      "\n",
      "GeneName       ZZEF1      ZZZ3  \n",
      "Expression  5.199194  4.066042  \n",
      "Expression  5.199194  4.066042  \n",
      "Expression  5.199194  4.066042  \n",
      "Expression  5.199194  4.066042  \n",
      "Expression  5.199194  4.066042  \n",
      "...              ...       ...  \n",
      "Expression  5.199194  4.066042  \n",
      "Expression  5.199194  4.066042  \n",
      "Expression  5.199194  4.066042  \n",
      "Expression  5.199194  4.066042  \n",
      "Expression  5.199194  4.066042  \n",
      "\n",
      "[1000 rows x 20012 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load your actual bulk RNAseq data\n",
    "# Make sure to adjust the path to the file containing your data\n",
    "cfrna_data = pd.read_csv('./Dataset/arp3_protein_coding_feature_counts.txt',\n",
    "                         sep='\\t', header=None, names=['gene_names', 'counts'])\n",
    "\n",
    "# Convert counts to float\n",
    "cfrna_data['counts'] = cfrna_data['counts'].astype(float)\n",
    "\n",
    "# Normalize the cfRNAseq data\n",
    "cpm = cfrna_data['counts'] / cfrna_data['counts'].sum() * 1e6\n",
    "log_cpm = np.log1p(cpm)\n",
    "\n",
    "# Create a DataFrame with gene names and normalized expression values\n",
    "cfrna_df = pd.DataFrame({'GeneName': cfrna_data['gene_names'], 'Expression': log_cpm})\n",
    "\n",
    "# Set the GeneName column as the index of cfRNA_df\n",
    "cfrna_df = cfrna_df.set_index('GeneName')\n",
    "print(\"Contents of cfrna_data:\\n\", cfrna_df)\n",
    "\n",
    "# Transpose to match X\n",
    "cfrna_df = cfrna_df.transpose()\n",
    "\n",
    "# Alphabetically ordering the genes\n",
    "cfrna_df = cfrna_df.sort_index(axis=1)\n",
    "cfrna_df = cfrna_df.append([cfrna_df]*999)\n",
    "print(\"Contents of cfrna_df:\\n\", cfrna_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da1834e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50fa93a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading scRNA-seq data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-192846d06f5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# LOAD SCRNA-SEQ DATA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loading scRNA-seq data...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0madata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_h5ad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./Dataset/TabulaSapiens.h5ad\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbacked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loaded scRNAseq data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\anndata\\_io\\h5ad.py\u001b[0m in \u001b[0;36mread_h5ad\u001b[1;34m(filename, backed, as_sparse, as_sparse_fmt, chunk_size)\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"r+\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r+\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mread_h5ad_backed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mas_sparse_fmt\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsc_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\anndata\\_io\\h5ad.py\u001b[0m in \u001b[0;36mread_h5ad_backed\u001b[1;34m(filename, mode)\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mread_elem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_read_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"var\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"varm\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\anndata\\_io\\h5ad.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mread_elem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_read_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"var\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"varm\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\anndata\\_io\\specs\\registry.py\u001b[0m in \u001b[0;36mread_elem\u001b[1;34m(elem, modifiers)\u001b[0m\n\u001b[0;32m    181\u001b[0m ) -> Any:\n\u001b[0;32m    182\u001b[0m     \u001b[1;34m\"\"\"Read an element from an on disk store.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_REGISTRY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodifiers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\anndata\\_io\\specs\\methods.py\u001b[0m in \u001b[0;36mread_mapping\u001b[1;34m(elem)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_REGISTRY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZarrGroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIOSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dict\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"0.1.0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mread_elem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\anndata\\_io\\specs\\methods.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_REGISTRY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZarrGroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIOSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dict\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"0.1.0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mread_elem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\anndata\\_io\\specs\\registry.py\u001b[0m in \u001b[0;36mread_elem\u001b[1;34m(elem, modifiers)\u001b[0m\n\u001b[0;32m    181\u001b[0m ) -> Any:\n\u001b[0;32m    182\u001b[0m     \u001b[1;34m\"\"\"Read an element from an on disk store.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_REGISTRY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodifiers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\anndata\\_io\\specs\\methods.py\u001b[0m in \u001b[0;36mread_sparse\u001b[1;34m(elem)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_REGISTRY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZarrGroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIOSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"csr_matrix\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"0.1.0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mSparseDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\anndata\\_core\\sparse_dataset.py\u001b[0m in \u001b[0;36mto_memory\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[0mmtx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[0mmtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mmtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"indices\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[0mmtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"indptr\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmtx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine_learning\\lib\\site-packages\\h5py\\_hl\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, args, new_dtype)\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fast_read_ok\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fast_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m                 \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Fall back to Python read pathway below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LOAD SCRNA-SEQ DATA\n",
    "print(\"Loading scRNA-seq data...\")\n",
    "adata = sc.read_h5ad(filename = \"./Dataset/TabulaSapiens.h5ad\", backed='r')\n",
    "\n",
    "print(\"Loaded scRNAseq data\")\n",
    "\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7188a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESS INTERSECTED SCRNASEQ DATASET USING THE PROCESSED EXPRESSION VALUES, NOT RAW COUNTS --> SKIP IF USING RAW COUNTS\n",
    "# NOT USEFUL FOR SIMULATION\n",
    "print(\"Normalizing and filtering scRNA-seq data...\")\n",
    "# print(\"Sum of data after loading:\", np.sum(scrnaseq_data.X))\n",
    "\n",
    "# NORMALIZE SC_RNASEQ DATA\n",
    "print(\"Before normalization and filtering:\", scrnaseq_data.shape)\n",
    "sc.pp.normalize_total(scrnaseq_data, target_sum=1e6)\n",
    "print(\"After normalization:\", scrnaseq_data.shape)\n",
    "sc.pp.log1p(scrnaseq_data)\n",
    "print(\"After logarithmization:\", scrnaseq_data.shape)\n",
    "\n",
    "# print(\"Normalized scRNAseq data\")\n",
    "\n",
    "# FILTER SC_RNASEQ DATA\n",
    "print(\"\\nFiltering scRNAseq data\")\n",
    "\n",
    "scrnaseq_data.raw = scrnaseq_data\n",
    "min_genes = 500\n",
    "max_mito = 0.05\n",
    "mito_genes = scrnaseq_data.var_names.str.startswith('mt-')\n",
    "scrnaseq_data.obs['percent_mito'] = np.sum(scrnaseq_data[:, mito_genes].X, axis=1) / np.sum(scrnaseq_data.X, axis=1)\n",
    "scrnaseq_data.obs['n_genes'] = np.sum(scrnaseq_data.X > 0, axis=1)\n",
    "scrnaseq_data = scrnaseq_data[scrnaseq_data.obs['n_genes'] > min_genes, :]\n",
    "scrnaseq_data = scrnaseq_data[scrnaseq_data.obs['percent_mito'] < max_mito, :]\n",
    "\n",
    "print(\"Filtered scRNAseq data\")\n",
    "print(\"After filtering:\", scrnaseq_data.shape)\n",
    "\n",
    "print(\"\\nPerforming feature selection...\")\n",
    "\n",
    "# FEATURE SELECTION\n",
    "print(\"Before feature selection:\", scrnaseq_data.shape)\n",
    "sc.pp.highly_variable_genes(scrnaseq_data, n_top_genes=6000)\n",
    "scrnaseq_data_fs = scrnaseq_data[:, scrnaseq_data.var['highly_variable']]\n",
    "\n",
    "# # STANDARD SCALING\n",
    "# scaler = StandardScaler()\n",
    "# scaled_scrnaseq_data = scaler.fit_transform(scrnaseq_data_fs.X)\n",
    "# scrnaseq_data_fs.X = scaled_scrnaseq_data\n",
    "\n",
    "# Use scanpy's integrated scaling algorithm\n",
    "sc.pp.scale(scrnaseq_data_fs, max_value=10)\n",
    "print(\"Any NaN in adata after scaling:\", np.isnan(scrnaseq_data_fs.X).any())\n",
    "# Store the means and standard deviations for applying to the cfRNA data\n",
    "gene_means = scrnaseq_data_fs.var['mean']\n",
    "gene_stds = scrnaseq_data_fs.var['std']\n",
    "\n",
    "print(\"After feature selection:\", scrnaseq_data_fs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633b8f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6a211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE INTERSECTED PREPROCESSED SCRNASEQ DATA FOR SIMULATION --> USES RAW COUNTS, NOT PROCESSED EXPRESSION DATA\n",
    "print(\"Preparing input data...\")\n",
    "\n",
    "# Extract cluster labels\n",
    "cell_type_labels = scrnaseq_data.obs['cell_ontology_class']\n",
    "print(\"Cell type labels extracted.\")\n",
    "print(\"\\nUnique cell_type_labels labels:\\n\", cell_type_labels.unique(), sep='\\n')\n",
    "\n",
    "# Convert the sparse matrix to a dense array\n",
    "dense_X = scrnaseq_data.X.toarray() if sparse.issparse(scrnaseq_data.X) else scrnaseq_data.X\n",
    "# Convert adata.X to DataFrame\n",
    "expression_data = pd.DataFrame(dense_X, columns=scrnaseq_data.var_names)\n",
    "print(\"Converted scrnaseq_data.X to DataFrame.\")\n",
    "print(\"\\nContents of expression_data before adding cluster labels:\\n\", expression_data.head())\n",
    "\n",
    "# Convert cell type labels to a regular series with the same index as expression_data\n",
    "cell_type_labels = pd.Series(cell_type_labels.values, index=expression_data.index, name='cell_type')\n",
    "print(\"--> Converted cluster labels to a regular series.\")\n",
    "print(\"\\n--> Added cell labels to scRNAseq dataframe\")\n",
    "\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(\"\\nAll unique cell ontology class counts in the scRNAseq data:\\n\\n\", pd.Series(cell_type_labels.value_counts()))\n",
    "\n",
    "# Insert cell_type_labels as the first column in expression_data\n",
    "expression_data.insert(0, 'cell', cell_type_labels)\n",
    "\n",
    "print(\"\\nscRNAseq dataframe with cell type labels:\\n\\n\", expression_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d040fef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_learning] *",
   "language": "python",
   "name": "conda-env-machine_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
